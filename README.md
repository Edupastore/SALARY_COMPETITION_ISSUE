# SALARY_COMPETITION_Proyect

![elsdiners](https://github.com/Edupastore/SALARY_COMPETITION_ISSUE/blob/main/img/dineritus.jfif)


## ‚õìÔ∏è √çndice de contenidos

1.[‚úçÔ∏è Descripci√≥n del proyecto](#descripci√≥n)\
2.[üëÄ Exploraci√≥n y preparaci√≥n de los datos (an√°lisis y limpieza)](#limpieza)\
3.[üìà Entrenamiento y testeo de modelos de Machine Learning](#traintest)\
4.[‚è´ Resultados: mejor modelo](#resultados)\

## ‚úçÔ∏è Descripci√≥n

Este proyecto trata sobre una competici√≥n en la plataforma Kaggle, cuya meta es predecir el salario de los trabajos de cient√≠ficos de datos en USD. Para ello, exploraremos y limpiaremos unos datos contenidos en un fichero csv llamado "salaries_data", para despu√©s entrenar un modelo de Machine Learning y posteriormente testear y subir la muestra a Kaggle con el objetivo de reducir el RMSE (evaluamos el error) en el salario que tratamos de predecir.

## üëÄ Exploraci√≥n y preparaci√≥n de los datos (an√°lisis y limpieza)

Para limpiar los datos, hemos seguido los siguientes pasos:

- Hemos explorado nuestro dataset para ver a qu√© nos enfrent√°bamos; hemos observado que no hay nulos.
- Hemos prescindido de varias columnas al pensar que no ten√≠an peso a la hora de poder predecir nuestra variable objetivo.
- Hemos hecho una serie de transformaciones en varias columnas para homogeneizar los datos.
- Las columnas categ√≥ricas las hemos transformado a n√∫mericas mediante get_dummies.
- Hemos chequeado las correlaciones entre las distintas variables y nuestra variable objetivo.
- Hemos comprobado que no hab√≠a registros duplicados.

## üìà Entrenamiento y testeo de modelos de Machine Learning

A continuaci√≥n, hemos hecho un split para separar los datos en datos de entrenamiento y de testeo (tanto para nuestras X, que son las variables, como para la Y, que es nuestra variable objetivo, o sea, los salarios en USD).

Al entrenar los datos pas√°ndole "lazy", hemos visto que el modelo que mejor se ajusta es el GammaRegressor; esto quiere decir que es el que nos devuelve menor error (RMSE) al hacer la predicci√≥n.

Para finalizar, hemos hecho el mismo proceso para la fase de testeo y hemos exportado los datos a un csv llamado salary_predict_usd que hemos subido a Kaggle.

## ‚è´ Resultados: mejor modelo

Como hemos comentado en el ep√≠grafe anterior, el modelo que mejor se ajusta a los datos con los que hemos trabajado es el GammaRegressor.

Al subir el fichero a Kaggle, hemos visto que la puntuaci√≥n que hemos obtenido es de 43118.12176 y el ranking p√∫blico nos eleva a la d√©cima posici√≥n:

![posizione](https://github.com/Edupastore/SALARY_COMPETITION_ISSUE/blob/main/img/ranking.jpg)
